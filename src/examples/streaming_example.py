"""ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ë³´ì—¬ì£¼ëŠ” ì˜ˆì œ.

ì´ ì˜ˆì œëŠ” ConversationAgentì˜ chat_stream ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬
ì‹¤ì‹œê°„ìœ¼ë¡œ ì‘ë‹µì„ í‘œì‹œí•©ë‹ˆë‹¤.

ì‚¬ìš© ë°©ë²•:
    $ uv run python examples/streaming_example.py

ê¸°ëŠ¥:
    - ì‹¤ì‹œê°„ í† í° ìŠ¤íŠ¸ë¦¬ë°
    - íƒ€ì´í•‘ íš¨ê³¼
    - ì‘ë‹µ ì‹œê°„ ì¸¡ì •
    - ì—¬ëŸ¬ ì§ˆë¬¸ ìˆœì°¨ ì²˜ë¦¬
    - Rich ë¼ì´ë¸ŒëŸ¬ë¦¬ UI

Example:
    >>> python examples/streaming_example.py
    ì§ˆë¬¸ 1/3: íŒŒì´ì¬ì´ë€?
    ğŸ¤– íŒŒì´ì¬ì€ ê³ ìˆ˜ì¤€ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤...
    â±ï¸  ì‘ë‹µ ì‹œê°„: 2.34ì´ˆ
"""

import asyncio
import os
import time
from pathlib import Path

from dotenv import load_dotenv

from agent_framework import ChatAgent
from agent_framework.azure import AzureOpenAIChatClient
from rich.console import Console
from rich.live import Live
from rich.markdown import Markdown
from rich.panel import Panel
from rich.progress import BarColumn, Progress, SpinnerColumn, TextColumn
from rich.text import Text

# Load environment variables from .env file
load_dotenv()

console = Console()


async def stream_response(
    agent: ChatAgent, question: str, question_num: int, total: int
) -> tuple[str, float]:
    """ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì‘ë‹µì„ ë°›ì•„ í‘œì‹œí•©ë‹ˆë‹¤.

    Args:
        agent: ChatAgent ì¸ìŠ¤í„´ìŠ¤
        question: ì‚¬ìš©ì ì§ˆë¬¸
        question_num: í˜„ì¬ ì§ˆë¬¸ ë²ˆí˜¸
        total: ì „ì²´ ì§ˆë¬¸ ê°œìˆ˜

    Returns:
        ì™„ì „í•œ ì‘ë‹µ í…ìŠ¤íŠ¸ì™€ ì†Œìš” ì‹œê°„(ì´ˆ)
    """
    # ì§ˆë¬¸ í‘œì‹œ
    console.print()
    console.print(
        Panel(
            Text(question, style="bold cyan"),
            title=f"[bold yellow]ì§ˆë¬¸ {question_num}/{total}[/bold yellow]",
            border_style="cyan",
        )
    )
    console.print()

    # ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
    full_response = ""
    start_time = time.time()

    # Live displayë¡œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
    with Live(
        Panel(
            Text("", style="white"),
            title="[bold green]ğŸ¤– Assistant[/bold green]",
            border_style="green",
        ),
        console=console,
        refresh_per_second=10,
    ) as live:
        try:
            result = await agent.run(question)

            full_response = result.text

            # Simulate streaming for demo purposes
            for i in range(0, len(full_response), 5):
                chunk = full_response[i : i + 5]

                # Live display ì—…ë°ì´íŠ¸
                live.update(
                    Panel(
                        Markdown(full_response[: i + 5]),
                        title="[bold green]ğŸ¤– Assistant[/bold green]",
                        border_style="green",
                    )
                )
                await asyncio.sleep(0.05)  # Simulate streaming delay

        except Exception as e:
            console.print(f"[bold red]âŒ ì˜¤ë¥˜ ë°œìƒ: {e}[/bold red]")
            return "", 0.0

    elapsed_time = time.time() - start_time

    # ì‘ë‹µ ì™„ë£Œ í‘œì‹œ
    console.print()
    console.print(
        f"[dim]â±ï¸  ì‘ë‹µ ì‹œê°„: {elapsed_time:.2f}ì´ˆ "
        f"| í† í° ìˆ˜: ~{len(full_response.split())}ê°œ[/dim]"
    )

    return full_response, elapsed_time


async def run_streaming_demo() -> None:
    """ìŠ¤íŠ¸ë¦¬ë° ë°ëª¨ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    console.print(
        Panel.fit(
            "[bold cyan]ğŸš€ Streaming Chat Demo[/bold cyan]\n\n"
            "ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ í™•ì¸í•˜ì„¸ìš”!",
            border_style="cyan",
        )
    )
    console.print()

    # Agent ì´ˆê¸°í™”
    with console.status("[bold green]Agent ì´ˆê¸°í™” ì¤‘...", spinner="dots"):
        chat_client = AzureOpenAIChatClient(
            deployment_name=os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT_NAME", "gpt-4"),
            api_key=os.getenv("AZURE_OPENAI_KEY", None),
            endpoint=os.getenv("AZURE_OPENAI_ENDPOINT", None)
        )
        agent = ChatAgent(
            chat_client=chat_client,
            instructions="ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. "
            "ê°„ê²°í•˜ë©´ì„œë„ ìœ ìµí•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.",
        )

    console.print("[bold green]âœ… Agent ì¤€ë¹„ ì™„ë£Œ![/bold green]")
    console.print()

    # ë°ëª¨ ì§ˆë¬¸ë“¤
    questions = [
        "íŒŒì´ì¬ì˜ ì£¼ìš” íŠ¹ì§• 3ê°€ì§€ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•´ì¤˜.",
        "ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°ì´ë€ ë¬´ì—‡ì´ê³ , ì–¸ì œ ì‚¬ìš©í•˜ë©´ ì¢‹ì„ê¹Œ?",
        "FastAPIì™€ Flaskì˜ ì°¨ì´ì ì„ ë¹„êµí•´ì¤˜.",
        "íƒ€ì… íŒíŠ¸ë¥¼ ì‚¬ìš©í•˜ë©´ ì–´ë–¤ ì¥ì ì´ ìˆì–´?",
    ]

    total_time = 0.0
    responses = []

    # Progress bar ìƒì„±
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
        console=console,
    ) as progress:
        task = progress.add_task(
            "[cyan]ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘...", total=len(questions)
        )

        for i, question in enumerate(questions, start=1):
            response, elapsed = await stream_response(
                agent, question, i, len(questions)
            )

            if response:
                responses.append((question, response, elapsed))
                total_time += elapsed

            progress.advance(task)

            # ë§ˆì§€ë§‰ ì§ˆë¬¸ì´ ì•„ë‹ˆë©´ êµ¬ë¶„ì„  í‘œì‹œ
            if i < len(questions):
                console.print()
                console.print("â”€" * console.width, style="dim")

    # ìµœì¢… í†µê³„
    console.print()
    console.print()
    console.print(
        Panel.fit(
            f"[bold cyan]ğŸ“Š ì„¸ì…˜ í†µê³„[/bold cyan]\n\n"
            f"ì²˜ë¦¬ëœ ì§ˆë¬¸: {len(responses)}/{len(questions)}ê°œ\n"
            f"ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ\n"
            f"í‰ê·  ì‘ë‹µ ì‹œê°„: {total_time / len(responses):.2f}ì´ˆ\n"
            f"ì´ í† í° ìˆ˜ (ì¶”ì •): ~{sum(len(r[1].split()) for r in responses)}ê°œ",
            border_style="cyan",
        )
    )

    # ëŒ€í™” ì €ì¥ ì˜µì…˜
    console.print()
    save = console.input(
        "[bold yellow]ëŒ€í™”ë¥¼ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): [/bold yellow]"
    )

    if save.lower() in ("y", "yes"):
        filepath = Path("data/streaming_demo.json")
        try:
            # Note: Agent Framework doesn't have built-in save functionality
            # This would need custom implementation
            console.print(
                f"[bold yellow]â„¹ï¸  ëŒ€í™” ì €ì¥ ê¸°ëŠ¥ì€ ë³„ë„ êµ¬í˜„ì´ í•„ìš”í•©ë‹ˆë‹¤.[/bold yellow]"
            )
        except Exception as e:
            console.print(f"[bold red]âŒ ì €ì¥ ì‹¤íŒ¨: {e}[/bold red]")


async def run_interactive_streaming() -> None:
    """ëŒ€í™”í˜• ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    console.print(
        Panel.fit(
            "[bold cyan]ğŸ’¬ Interactive Streaming Mode[/bold cyan]\n\n"
            "ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ ì‹¤ì‹œê°„ìœ¼ë¡œ ì‘ë‹µì„ ë°›ìŠµë‹ˆë‹¤.\n"
            "'exit' ë˜ëŠ” 'quit'ë¥¼ ì…ë ¥í•˜ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.",
            border_style="cyan",
        )
    )
    console.print()

    # Agent ì´ˆê¸°í™”
    chat_client = AzureOpenAIChatClient(
        deployment_name=os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT_NAME", "gpt-4"),
        api_key=os.getenv("AZURE_OPENAI_KEY", None),
        endpoint=os.getenv("AZURE_OPENAI_ENDPOINT", None)
    )
    agent = ChatAgent(
        chat_client=chat_client,
        instructions="ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.",
    )

    question_count = 0

    while True:
        console.print()
        question = console.input("[bold cyan]ğŸ§‘ You: [/bold cyan]")

        if question.lower() in ("exit", "quit"):
            console.print()
            console.print("[bold yellow]ğŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.[/bold yellow]")
            break

        if not question.strip():
            continue

        question_count += 1

        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
        await stream_response(agent, question, question_count, "?")

    # í†µê³„ í‘œì‹œ (Agent FrameworkëŠ” ë©”íŠ¸ë¦­ ê¸°ëŠ¥ì´ ì œí•œì )
    console.print()
    console.print(
        Panel.fit(
            f"[bold cyan]ğŸ“Š ì„¸ì…˜ í†µê³„[/bold cyan]\n\n"
            f"ì´ ì§ˆë¬¸: {question_count}ê°œ",
            border_style="cyan",
        )
    )


def main() -> None:
    """ë©”ì¸ í•¨ìˆ˜."""
    console.print()
    console.print(
        "[bold cyan]Streaming Example - ì‹¤í–‰ ëª¨ë“œ ì„ íƒ[/bold cyan]"
    )
    console.print()
    console.print("1. ë°ëª¨ ëª¨ë“œ (ë¯¸ë¦¬ ì •ì˜ëœ ì§ˆë¬¸)")
    console.print("2. ëŒ€í™”í˜• ëª¨ë“œ (ììœ ë¡­ê²Œ ì§ˆë¬¸)")
    console.print()

    choice = console.input("[bold yellow]ì„ íƒ (1/2): [/bold yellow]")

    if choice == "1":
        asyncio.run(run_streaming_demo())
    elif choice == "2":
        asyncio.run(run_interactive_streaming())
    else:
        console.print("[bold red]ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.[/bold red]")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        console.print()
        console.print("[bold yellow]ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.[/bold yellow]")
    except Exception as e:
        console.print()
        console.print(f"[bold red]âŒ ì˜¤ë¥˜ ë°œìƒ: {e}[/bold red]")
